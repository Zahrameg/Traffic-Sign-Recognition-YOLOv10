# -*- coding: utf-8 -*-
"""Prétraitement_des_données_Version1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i4dL1dtOxs9Mz2nNHQsuiqsbclqPEpvC
"""

import os
import shutil
import random
import cv2
import matplotlib.pyplot as plt
from collections import Counter

!pip install albumentations --quiet

import albumentations as A

import os
from collections import Counter
import matplotlib.pyplot as plt


def analyze_and_plot_class_occurrences(label_dir):

    class_counts = Counter()


    for lbl_file in os.listdir(label_dir):
        if not lbl_file.endswith(".txt"):
            continue

        with open(os.path.join(label_dir, lbl_file), 'r') as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    class_counts[class_id] += 1

    print("Occurrences des classes :")
    for class_id, count in class_counts.items():
        print(f"Classe {class_id}: {count} occurrences")


    classes = list(class_counts.keys())
    occurrences = list(class_counts.values())

    plt.figure(figsize=(12, 6))
    plt.bar(classes, occurrences, color='skyblue')
    plt.xlabel("Classes")
    plt.ylabel("Occurrences")
    plt.title("Occurrences des classes dans les annotations")
    plt.xticks(classes, rotation=90)
    plt.tight_layout()
    plt.show()


label_dir = "/content/drive/MyDrive/DATASIGNALISATION/train/labels"
analyze_and_plot_class_occurrences(label_dir)

from google.colab import drive
drive.mount('/content/drive')

BASE_DIR = "/content/drive/MyDrive/DATASIGNALISATION"

# Dossier brut : images + labels
TRAIN_IMAGE = os.path.join(BASE_DIR, "train", "images")
TRAIN_LABEL = os.path.join(BASE_DIR, "train", "labels")

# Dossier nettoyé
CLEANED_IMAGE = os.path.join(BASE_DIR, "cleaned_images")
CLEANED_LABEL = os.path.join(BASE_DIR, "cleaned_labels")
os.makedirs(CLEANED_IMAGE, exist_ok=True)
os.makedirs(CLEANED_LABEL, exist_ok=True)

# Dossier filtré (pour classes rares)
FILTERED_IMAGE = os.path.join(BASE_DIR, "filtered_images")
FILTERED_LABEL = os.path.join(BASE_DIR, "filtered_labels")
os.makedirs(FILTERED_IMAGE, exist_ok=True)
os.makedirs(FILTERED_LABEL, exist_ok=True)

# Dossier fusionné (si tu fais un mapping de classes)
FUSED_IMAGE = os.path.join(BASE_DIR, "fused_images")
FUSED_LABEL = os.path.join(BASE_DIR, "fused_labels")

# Dossier pour l’augmentation
AUG_IMAGE = os.path.join(BASE_DIR, "aug_images")
AUG_LABEL = os.path.join(BASE_DIR, "aug_labels")

# Dossier final (split train/val/test)
FINAL_DATA_DIR = os.path.join(BASE_DIR, "final_dataset")
for s in ["train", "val", "test"]:
    os.makedirs(os.path.join(FINAL_DATA_DIR, s, "images"), exist_ok=True)
    os.makedirs(os.path.join(FINAL_DATA_DIR, s, "labels"), exist_ok=True)

def analyze_distribution(label_dir):
    """
    Retourne un dictionnaire {class_id: occurrences} pour des annotations YOLO.
    """
    counts = Counter()
    for f in os.listdir(label_dir):
        if f.endswith(".txt"):
            with open(os.path.join(label_dir, f), 'r') as lbl:
                lines = lbl.readlines()
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        cls_id = parts[0]
                        counts[cls_id] += 1
    return counts

def plot_class_distribution(class_counts, title="Distribution des classes"):
    """
    Affiche un histogramme (bar chart) pour visualiser la distribution.
    """
    plt.figure(figsize=(12, 6))
    classes = list(class_counts.keys())
    occurrences = list(class_counts.values())
    plt.bar(classes, occurrences, color='skyblue')
    plt.title(title)
    plt.xlabel("Classe")
    plt.ylabel("Occurrences")
    plt.xticks(rotation=90)
    plt.tight_layout()
    plt.show()

def show_random_image_with_bboxes(image_dir, label_dir, nb_samples=1):
    """
    Affiche nb_samples images aléatoires avec leurs bounding boxes.
    """
    all_labels = [f for f in os.listdir(label_dir) if f.endswith('.txt')]
    if not all_labels:
        print("Aucun label trouvé.")
        return
    chosen_labels = random.sample(all_labels, min(nb_samples, len(all_labels)))
    for lbl_file in chosen_labels:
        base_name = lbl_file.replace('.txt', '')

        jpg_path = os.path.join(image_dir, base_name + '.jpg')
        png_path = os.path.join(image_dir, base_name + '.png')

        if os.path.exists(jpg_path):
            img_path = jpg_path
        elif os.path.exists(png_path):
            img_path = png_path
        else:
            print(f"Pas d'image correspondante pour {lbl_file}")
            continue

        # Lire l'image
        img = cv2.imread(img_path)
        if img is None:
            print(f"Impossible de lire l'image {img_path}")
            continue

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        H, W, _ = img.shape

        fig, ax = plt.subplots(1, figsize=(8,6))
        ax.imshow(img_rgb)
        ax.set_title(f"Image: {base_name}")

        # Lecture des bboxes
        lbl_path = os.path.join(label_dir, lbl_file)
        with open(lbl_path, 'r') as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue
                cls_id, x_c, y_c, w, h = parts
                try:
                    x_c, y_c, w, h = float(x_c), float(y_c), float(w), float(h)
                except ValueError:
                    continue

                # Convertir YOLO en rectangle
                box_w = w * W
                box_h = h * H
                box_x = (x_c - w/2)*W
                box_y = (y_c - h/2)*H

                rect = plt.Rectangle(
                    (box_x, box_y), box_w, box_h,
                    edgecolor='red', facecolor='none', linewidth=2
                )
                ax.add_patch(rect)
                ax.text(
                    box_x, box_y-5, f"Cls {cls_id}",
                    color='red', backgroundcolor='white', fontsize=9
                )

        plt.axis('off')
        plt.tight_layout()
        plt.show()

def clean_dataset(src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):

    nb_txt_deleted = 0
    nb_txt_kept = 0
    nb_img_kept = 0

    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)

    txt_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(".txt")]
    for lbl_file in txt_files:
        lbl_path = os.path.join(src_lbl_dir, lbl_file)
        base_name = lbl_file.replace('.txt', '')


        jpg_path = os.path.join(src_img_dir, base_name + '.jpg')
        png_path = os.path.join(src_img_dir, base_name + '.png')
        if os.path.exists(jpg_path):
            img_path = jpg_path
        elif os.path.exists(png_path):
            img_path = png_path
        else:

            nb_txt_deleted += 1
            print(f"[CLEAN] Orphelin (pas d'image) => on ignore {lbl_file}")
            continue

        with open(lbl_path, 'r') as f:
            lines = f.readlines()
        valid_lines = []
        for line in lines:
            parts = line.strip().split()

            if len(parts) != 5:

                continue
            cls_id, x_c, y_c, w, h = parts

            try:
                _cls = int(cls_id)
            except ValueError:

                continue

            try:
                _x = float(x_c)
                _y = float(y_c)
                _w = float(w)
                _h = float(h)
            except ValueError:

                continue

            if not (0 <= _x <= 1 and 0 <= _y <= 1 and 0 <= _w <= 1 and 0 <= _h <= 1):
                continue

            if _w < 0.001 or _h < 0.001:
                continue


            if _w > 0.99 or _h > 0.99:
                continue

            valid_lines.append(line)


        if len(valid_lines) == 0:

            nb_txt_deleted += 1
            print(f"[CLEAN] Corrompu/vidé => on ignore {lbl_file}")
        else:

            dst_img_path = os.path.join(dst_img_dir, os.path.basename(img_path))
            shutil.copy(img_path, dst_img_path)
            nb_img_kept += 1


            dst_lbl_path = os.path.join(dst_lbl_dir, lbl_file)
            with open(dst_lbl_path, 'w') as fw:
                fw.writelines(valid_lines)
            nb_txt_kept += 1


    images_in_src = [f for f in os.listdir(src_img_dir) if f.lower().endswith(('.jpg', '.png'))]
    for img_file in images_in_src:
        base_name = os.path.splitext(img_file)[0]
        label_txt = os.path.join(src_lbl_dir, base_name + ".txt")

        if not os.path.exists(label_txt):

            print(f"[CLEAN - OPTION] Image orpheline : {img_file} (pas de .txt)")


    print(f"[CLEAN] {nb_txt_deleted} labels invalides ou orphelins ignorés.")
    print(f"[CLEAN] {nb_txt_kept} labels conservés, {nb_img_kept} images copiées.")
    print("[CLEAN] Nettoyage (copie) terminé.\n")


def update_data_yaml(train_img_dir, val_img_dir, test_img_dir, nc, names, yaml_path):

    data = {
        "train": train_img_dir,
        "val": val_img_dir,
        "test": test_img_dir,
        "nc": nc,
        "names": names
    }
    with open(yaml_path, 'w') as f:
        yaml.dump(data, f, sort_keys=False)
    print(f"Fichier YAML mis à jour : {yaml_path}")

print("===== BEFORE CLEANING =====")
before_counts = analyze_distribution(TRAIN_LABEL)
print("Distribution AVANT nettoyage :", before_counts)
plot_class_distribution(before_counts, "Distribution AVANT Nettoyage")

print("===== Nettoyage en cours... =====")
clean_dataset(
    src_img_dir=TRAIN_IMAGE,
    src_lbl_dir=TRAIN_LABEL,
    dst_img_dir=CLEANED_IMAGE,
    dst_lbl_dir=CLEANED_LABEL
)

print("===== AFTER CLEANING =====")
after_counts = analyze_distribution(CLEANED_LABEL)
print("Distribution APRÈS nettoyage :", after_counts)
plot_class_distribution(after_counts, "Distribution APRÈS Nettoyage")

print("===== SHOWING RANDOM IMAGE BEFORE CLEANING =====")
show_random_image_with_bboxes(TRAIN_IMAGE, TRAIN_LABEL, nb_samples=5)

print("===== SHOWING RANDOM IMAGE AFTER CLEANING =====")
show_random_image_with_bboxes(CLEANED_IMAGE, CLEANED_LABEL, nb_samples=5)

import os
import shutil
import random
import cv2
import matplotlib.pyplot as plt
from collections import Counter
import albumentations as A

# Liste complète des classes
class_names = ['0', '1', '100', '101', '102', '103', '105', '106', '107',
               '108', '109', '110', '111', '112', '113', '115', '116', '117',
               '12', '120', '121', '122', '123', '124', '125', '127', '128',
               '129', '131', '132', '133', '136', '137', '138', '139', '140',
               '141', '142', '143', '144', '145', '146', '147', '148', '149',
               '15', '150', '153', '154', '155', '156', '158', '159', '16', '161',
               '163', '164', '166', '167', '168', '169', '17', '170', '171', '172',
               '173', '174', '175', '177', '178', '179', '18', '180', '181', '19',
               '2', '20', '21', '22', '23', '24', '27', '28', '29', '3', '31', '32',
               '33', '34', '35', '36', '39', '4', '40', '41', '42', '43', '45', '46',
               '47', '48', '49', '5', '50', '50 meters between vehicles', '51', '52',
               '53', '54', '55', '56', '57', '59', '60', '62', '63', '64', '65', '66',
               '67', '68', '69', '70', '71', '73',
               '74', '76', '78', '79', '8', '81', '82', '83', '84', '85', '86', '87',
               '88', '89', '90', '91', '93', '94', '95', '97', '98', '99',
    'Advance direction sign exit ahead from other road than motorway or expressway',
    'Axle weight limit-2ton',
    'Bus stop',
    'Cattle',
    'Crossroad intersection',
    'Crossroads',
    'Cycle track',
    'Cyclist and mopeds rides on carrigeway',
    'Cyclists',
    'Dangerous shoulder',
    'Dip',
    'Direction sign exit sign',
    'Direction to be followed',
    'End of all restrictions',
    'End of lane reserved for public transport',
    'Falling rocks',
    'Filling station',
    'First aid post',
    'Give way (Yield)',
    'Give way -Yield-',
    'Guarded level crossing ahead',
    'Height limit-3.5m',
    'Horn prohibited',
    'Hotel',
    'Keep left',
    'Left curve',
    'Level crossing countdown marker',
    'Loose gravel',
    'Main highways',
    'Marking for sharp bends',
    'Motorway',
    'Narrow bridge',
    'Narrow road',
    'National border',
    'No Left turn',
    'No Right turn',
    'No entry',
    'No entry for Trucks',
    'No entry for bicycles',
    'No entry for bullock carts',
    'No entry for hand carts',
    'No entry for motor vehicles',
    'No entry for pedestrians',
    'No parking',
    'No passing',
    'No snowmobiles',
    'No stopping',
    'No vehicles exceeding 12 tonnes',
    'No vehicles exceeding length shown',
    'No vehicles in both directions',
    'No vehicles or combination of vehicles exceeding weight shown',
    'Oblique side road junction',
    'One-way traffic',
    'Parking',
    'Parking allowed for 15min',
    'Passing without stopping prohibited',
    'Pedestrian crossing',
    'Priority over oncoming vehicles',
    'Refreshments',
    'Restaurant',
    'Restriction zone',
    'Right curve',
    'Road hump',
    'Road number sign',
    'Roadworks',
    'Roundabout',
    'School',
    'Side road junction',
    'Slippery road',
    'Speed refulcation bump',
    'Staggered side road junction',
    'Steep ascent',
    'Steep descent',
    'Steep downhill',
    'Steep uphill',
    'Stop',
    'Stop at customs',
    'Straight ahead',
    'Symbol plate for specified vehicle or road user category',
    'T-junction',
    'Telephone',
    'Traffic signals',
    'Turn Right',
    'Turn left ahead',
    'Turn left or straight ahead',
    'Turn right ahead',
    'Uneven road',
    'Unguarded level crossing ahead',
    'Unprotected quay',
    'Weight limit-5ton',
    'Y-junction',
    'adjoining way',
    'axle weight limit 30tonnes',
    'end of the speed limit',
    'exit',
    'falling rocks (from) left',
    'falling rocks -from- left',
    'length limit-10m',
    'lowspeed zone',
    'no entry for bicycles and humans',
    'no motorcycles',
    'no turning left',
    'no u turn',
    'snowmobiles',
    'speed limit-100',
    'speed limit-110',
    'speed limit-30',
    'speed limit-50',
    'speed limit-60',
    'speed limit-70',
    'speed limit-80',
    'speed limit-90',
    'speed-limit-120',
    'tunnel in 2 km',
    'two way traffic',
    'warning wild animal'
]

# Assignation des Class IDs
class_id_mapping = {class_name: idx for idx, class_name in enumerate(class_names)}
reverse_class_id_mapping = {idx: class_name for class_name, idx in class_id_mapping.items()}

print("Mapping des Class IDs:")
for class_name, class_id in class_id_mapping.items():
    print(f"ID {class_id}: {class_name}")

import os
def show_one_image_for_specified_classes(image_dir, label_dir, target_classes):

    # Dictionnaire pour stocker une image par classe
    image_per_class = {class_id: None for class_id in target_classes}

    for lbl_file in os.listdir(label_dir):
        if not lbl_file.endswith(".txt"):
            continue

        base_name = lbl_file.replace(".txt", "")
        jpg_path = os.path.join(image_dir, base_name + ".jpg")
        png_path = os.path.join(image_dir, base_name + ".png")

        img_path = None
        if os.path.exists(jpg_path):
            img_path = jpg_path
        elif os.path.exists(png_path):
            img_path = png_path
        else:
            continue


        with open(os.path.join(label_dir, lbl_file), "r") as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    if class_id in target_classes and image_per_class[class_id] is None:
                        image_per_class[class_id] = img_path
    for class_id, img_path in image_per_class.items():
        if img_path is not None:
            print(f"Classe {class_id} (Image: {os.path.basename(img_path)})")
            # Charger et afficher l'image
            img = cv2.imread(img_path)
            if img is not None:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                plt.figure(figsize=(8, 6))
                plt.imshow(img_rgb)
                plt.title(f"Classe: {class_id}")
                plt.axis("off")
                plt.show()
        else:
            print(f"Aucune image trouvée pour la classe {class_id}.")

# Exemple d'utilisation
image_dir = "/content/drive/MyDrive/DATASIGNALISATION/train/images"
label_dir = "/content/drive/MyDrive/DATASIGNALISATION/train/labels"
target_classes = list(range(0, 146))  # IDs de 0 à 146
show_one_image_for_specified_classes(image_dir, label_dir, target_classes)

exclusion_str = ("0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,20,21,25,30,31,"
                 "33,34,35,37,38,39,40,41,42,43,45,46,47,48,49,54,55,56,57,58,56,"
                 "60,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,79,80,81,82,"
                 "83,84,85,86,87,89,90,91,92,93,95,97,98,99,100,101,104,105,106,"
                 "107,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,"
                 "124,125,127,128,129,130,131,132,135,136,137,138,139,140,141,142,"
                 "143,144")
CLASSES_A_EXCLURE = exclusion_str.split(",")
def filter_labels_by_class(src_lbl_dir, dst_lbl_dir, classes_to_exclude):
    """
    Copie les fichiers de label depuis src_lbl_dir vers dst_lbl_dir en excluant
    les annotations dont le premier token (classe) appartient à classes_to_exclude.
    """
    os.makedirs(dst_lbl_dir, exist_ok=True)
    for lbl_file in os.listdir(src_lbl_dir):
        if not lbl_file.endswith(".txt"):
            continue
        src_path = os.path.join(src_lbl_dir, lbl_file)
        with open(src_path, "r") as f:
            lines = f.readlines()
        kept_lines = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) == 5:
                cls_id = parts[0]
                if cls_id not in CLASSES_A_EXCLURE:
                    kept_lines.append(line)
        if kept_lines:
            with open(os.path.join(dst_lbl_dir, lbl_file), "w") as fw:
                fw.writelines(kept_lines)

# Application du filtrage

FILTERED_LABEL_DIR = os.path.join(BASE_DIR, "filtered_labels")
os.makedirs(FILTERED_LABEL_DIR, exist_ok=True)


filter_labels_by_class(CLEANED_LABEL, FILTERED_LABEL_DIR, CLASSES_A_EXCLURE)


new_filtered_distribution = analyze_distribution(FILTERED_LABEL_DIR)
print("Distribution après filtrage :", new_filtered_distribution)
plot_class_distribution(new_filtered_distribution, "Distribution après filtrage")

# Copie des images associées aux labels filtrés pour garder la correspondance
FILTERED_IMAGE_OUT = os.path.join(BASE_DIR, "filtered_images_out")
os.makedirs(FILTERED_IMAGE_OUT, exist_ok=True)
def copy_images_for_filtered_labels(src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):
    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)
    label_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(".txt")]
    for lbl_file in label_files:
        base_name = lbl_file.replace(".txt", "")
        # Copier le label
        src_label_path = os.path.join(src_lbl_dir, lbl_file)
        dst_label_path = os.path.join(dst_lbl_dir, lbl_file)
        if os.path.realpath(src_label_path) != os.path.realpath(dst_label_path):
            shutil.copy2(src_label_path, dst_label_path)
        # Copier l'image correspondante (jpg ou png)
        for ext in [".jpg", ".png"]:
            candidate = os.path.join(src_img_dir, base_name + ext)
            if os.path.exists(candidate):
                dst_candidate = os.path.join(dst_img_dir, base_name + ext)
                if os.path.realpath(candidate) != os.path.realpath(dst_candidate):
                    shutil.copy2(candidate, dst_candidate)
                break

copy_images_for_filtered_labels(CLEANED_IMAGE, FILTERED_LABEL_DIR,
                                FILTERED_IMAGE_OUT, FILTERED_LABEL_DIR)
print("Copie des images/labels filtrés effectuée.")

# Mapping des classes pour la fusion
class_mapping = {
    "Axle weight limit-2ton": "Weight limit",
    "axle weight limit 30tonnes": "Weight limit",
    "Weight limit-5ton": "Weight limit",
    "speed limit-30": "Speed limit",
    "speed limit-50": "Speed limit",
    "speed limit-60": "Speed limit",
    "speed limit-70": "Speed limit",
    "speed limit-80": "Speed limit",
    "speed limit-90": "Speed limit",
    "speed limit-100": "Speed limit",
    "speed limit-110": "Speed limit",
    "speed-limit-120": "Speed limit",
    "lowspeed zone": "Speed limit",
    "falling rocks (from) left": "Falling rocks",
    "falling rocks -from- left": "Falling rocks",
    "No turning left": "No Left turn",
    "no u turn": "No U turn",
    "end of the speed limit": "End of all restrictions",
    "Parking allowed for 15min": "Parking"
}

# Application du  mapping pour fusionner les classes
def merge_classes_in_labels(src_lbl_dir, dst_lbl_dir, class_mapping, id_mapping):

    os.makedirs(dst_lbl_dir, exist_ok=True)
    for lbl_file in os.listdir(src_lbl_dir):
        if not lbl_file.endswith(".txt"):
            continue
        src_path = os.path.join(src_lbl_dir, lbl_file)
        with open(src_path, "r") as f:
            lines = f.readlines()

        new_lines = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) == 5:
                cls_id = parts[0]

                class_name = id_mapping.get(int(cls_id), None)
                if class_name and class_name in class_mapping:
                    new_class_name = class_mapping[class_name]

                    new_cls_id = list(id_mapping.keys())[list(id_mapping.values()).index(new_class_name)]
                    new_lines.append(f"{new_cls_id} {parts[1]} {parts[2]} {parts[3]} {parts[4]}\n")
                else:
                    new_lines.append(line)

        if new_lines:
            dst_path = os.path.join(dst_lbl_dir, lbl_file)
            with open(dst_path, "w") as fw:
                fw.writelines(new_lines)

FUSED_LABEL = os.path.join(BASE_DIR, "fused_labels")
FUSED_IMAGE = os.path.join(BASE_DIR, "fused_images")
os.makedirs(FUSED_LABEL, exist_ok=True)
os.makedirs(FUSED_IMAGE, exist_ok=True)

FILTERED_LABEL_OUT = os.path.join(BASE_DIR, "filtered_labels_out")
FILTERED_IMAGE_OUT = os.path.join(BASE_DIR, "filtered_images_out")
os.makedirs(FILTERED_LABEL_OUT, exist_ok=True)
os.makedirs(FILTERED_IMAGE_OUT, exist_ok=True)


def copy_images_for_filtered_labels(src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):
    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)
    label_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(".txt")]
    for lbl_file in label_files:
        base_name = lbl_file.replace(".txt", "")

        src_lbl_path = os.path.join(src_lbl_dir, lbl_file)
        dst_lbl_path = os.path.join(dst_lbl_dir, lbl_file)
        if os.path.realpath(src_lbl_path) != os.path.realpath(dst_lbl_path):
            shutil.copy2(src_lbl_path, dst_lbl_path)

        jpg_path = os.path.join(src_img_dir, base_name + ".jpg")
        png_path = os.path.join(src_img_dir, base_name + ".png")
        if os.path.exists(jpg_path):
            dst_jpg = os.path.join(dst_img_dir, base_name + ".jpg")
            if os.path.realpath(jpg_path) != os.path.realpath(dst_jpg):
                shutil.copy2(jpg_path, dst_jpg)
        elif os.path.exists(png_path):
            dst_png = os.path.join(dst_img_dir, base_name + ".png")
            if os.path.realpath(png_path) != os.path.realpath(dst_png):
                shutil.copy2(png_path, dst_png)

copy_images_for_filtered_labels(CLEANED_IMAGE, FILTERED_LABEL_DIR, FILTERED_IMAGE_OUT, FILTERED_LABEL_OUT)
def copy_images_for_fused_labels(src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):
    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)
    for lbl_file in os.listdir(src_lbl_dir):
        if lbl_file.endswith(".txt"):
            base_name = lbl_file.replace(".txt", "")
            src_lbl_path = os.path.join(src_lbl_dir, lbl_file)
            dst_lbl_path = os.path.join(dst_lbl_dir, lbl_file)
            if os.path.realpath(src_lbl_path) != os.path.realpath(dst_lbl_path):
                shutil.copy2(src_lbl_path, dst_lbl_path)
            jpg_path = os.path.join(src_img_dir, base_name + ".jpg")
            png_path = os.path.join(src_img_dir, base_name + ".png")
            if os.path.exists(jpg_path):
                dst_jpg = os.path.join(dst_img_dir, base_name + ".jpg")
                if os.path.realpath(jpg_path) != os.path.realpath(dst_jpg):
                    shutil.copy2(jpg_path, dst_jpg)
            elif os.path.exists(png_path):
                dst_png = os.path.join(dst_img_dir, base_name + ".png")
                if os.path.realpath(png_path) != os.path.realpath(dst_png):
                    shutil.copy2(png_path, dst_png)

copy_images_for_fused_labels(FILTERED_IMAGE_OUT, FUSED_LABEL, FUSED_IMAGE, FUSED_LABEL)

print("Fusion des classes réalisée")

# Visualiser la nouvelle distribution après fusion
new_distribution = analyze_distribution(FUSED_LABEL)
print("Nouvelle distribution des classes après fusion :")
print(new_distribution)
plot_class_distribution(new_distribution, "Distribution des classes après Fusion")

filtered_distribution = analyze_distribution(FILTERED_LABEL_DIR)
print("Classes restantes après filtrage :", filtered_distribution.keys())

merged_classes = []
for lbl_file in os.listdir(FUSED_LABEL):
    with open(os.path.join(FUSED_LABEL, lbl_file), 'r') as f:
        for line in f:
            merged_classes.append(line.split()[0])
print("Classes après fusion :", Counter(merged_classes))

TARGET_CLASSES_TO_AUGMENT = TARGET_CLASSES_TO_AUGMENT = ["25", "16", "15", "262", "26", "29", "256", "60", "203", "263", "102",
    "234", "53", "45", "70", "49", "9", "132", "140", "143", "146", "32",
    "184", "208", "147", "28", "22", "260", "151", "209", "217", "239",
    "213", "210", "108", "175", "50", "61", "52", "145", "261", "233",
    "206", "236", "165", "180", "250", "222", "191", "161", "253",
    "252", "169", "163", "103", "249", "207", "179", "193", "232", "218",
    "162", "238", "164", "223", "245", "183", "94", "24", "149", "215",
    "168", "230", "254", "181", "78", "257", "216", "27", "157", "154",
    "240", "198", "150", "226", "185", "23", "36", "244", "194", "225",
    "214", "247", "177", "202", "204", "148", "153", "171", "170", "192",
    "196", "231", "235", "219", "255", "195", "59"
]

num_augment = 2

# Définition des classes pour lesquelles on souhaite éviter la rotation:
arrow_classes = [
    "Turn Right",
    "Turn left ahead",
    "Turn left or straight ahead",
    "Turn right ahead",
    "Straight ahead",
    "Keep left",
    "Keep right",
    "Left curve",
    "Right curve",
    "U-turn",
    "No Left turn",
    "No Right turn",
    "No U turn"
]

# Pipeline de transformation avec rotation pour les images sans panneaux fléchés
transform_with_rotation = A.Compose([
    A.RandomBrightnessContrast(p=0.5),
    A.HorizontalFlip(p=0.5),
    A.RandomGamma(p=0.3),
    A.Rotate(limit=15, p=0.3)
], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

# Pipeline de transformation sans rotation pour préserver l'orientation des flèches
transform_without_rotation = A.Compose([
    A.RandomBrightnessContrast(p=0.5),
    A.HorizontalFlip(p=0.5),
    A.RandomGamma(p=0.3)
], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

def augment_dataset(src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir,
                    transform_with_rot, transform_without_rot,
                    target_classes_to_augment, num_augment=2):

    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)

    label_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(".txt")]
    for lbl_file in label_files:
        base_name = lbl_file.replace('.txt', '')

        img_path = None
        for ext in [".jpg", ".png"]:
            candidate = os.path.join(src_img_dir, base_name + ext)
            if os.path.exists(candidate):
                img_path = candidate
                break
        if img_path is None:
            continue


        img = cv2.imread(img_path)
        if img is None:
            continue
        H, W, _ = img.shape

        with open(os.path.join(src_lbl_dir, lbl_file), 'r') as f:
            lines = f.readlines()

        bboxes = []
        class_labels = []
        contains_target = False
        apply_rotation = True

        for line in lines:
            parts = line.strip().split()
            if len(parts) == 5:
                cls_id, x_c, y_c, w, h = parts
                bboxes.append([float(x_c), float(y_c), float(w), float(h)])
                class_labels.append(cls_id)

                if cls_id in target_classes_to_augment:
                    contains_target = True

                if cls_id in arrow_classes:
                    apply_rotation = False

        if not contains_target:
            continue

        shutil.copy2(img_path, os.path.join(dst_img_dir, os.path.basename(img_path)))
        with open(os.path.join(dst_lbl_dir, lbl_file), 'w') as fw:
            fw.writelines(lines)

        transform = transform_without_rot if not apply_rotation else transform_with_rot

        # Génération des images augmentées
        for i in range(num_augment):
            augmented = transform(image=img, bboxes=bboxes, class_labels=class_labels)
            aug_img = augmented['image']
            aug_bboxes = augmented['bboxes']
            aug_labels = augmented['class_labels']


            aug_img_name = f"{base_name}_aug{i}.jpg"
            cv2.imwrite(os.path.join(dst_img_dir, aug_img_name), aug_img)


            aug_label_name = f"{base_name}_aug{i}.txt"
            with open(os.path.join(dst_lbl_dir, aug_label_name), 'w') as fw:
                for bb, lab in zip(aug_bboxes, aug_labels):
                    x_c, y_c, w, h = bb
                    fw.write(f"{lab} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\n")

augment_dataset(FUSED_IMAGE, FUSED_LABEL, AUG_IMAGE, AUG_LABEL,
                transform_with_rotation, transform_without_rotation,
                target_classes_to_augment=TARGET_CLASSES_TO_AUGMENT, num_augment=num_augment)

print("Augmentation appliquée pour les classes spécifiées.")
print("Affichage de quelques images augmentées :")
show_random_image_with_bboxes(AUG_IMAGE, AUG_LABEL, nb_samples=3)

# Visualisation de la distribution après augmentation
aug_counts = analyze_distribution(AUG_LABEL)
print("Distribution après augmentation :", aug_counts)
plot_class_distribution(aug_counts, "Distribution après Augmentation")

def split_dataset(img_dir, lbl_dir, final_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):
    import random
    label_files = [f for f in os.listdir(lbl_dir) if f.endswith(".txt")]
    random.shuffle(label_files)
    n = len(label_files)
    t_end = int(n * train_ratio)
    v_end = int(n * (train_ratio + val_ratio))

    train_files = label_files[:t_end]
    val_files = label_files[t_end:v_end]
    test_files = label_files[v_end:]

    for s in ["train", "val", "test"]:
        os.makedirs(os.path.join(final_dir, s, "images"), exist_ok=True)
        os.makedirs(os.path.join(final_dir, s, "labels"), exist_ok=True)

    def copy_files(lbl_list, subset):
        for lblf in lbl_list:
            base = lblf.replace(".txt", "")
            shutil.copy2(os.path.join(lbl_dir, lblf),
                         os.path.join(final_dir, subset, "labels", lblf))
            jpgp = os.path.join(img_dir, base + ".jpg")
            pngp = os.path.join(img_dir, base + ".png")
            if os.path.exists(jpgp):
                shutil.copy2(jpgp, os.path.join(final_dir, subset, "images", base + ".jpg"))
            elif os.path.exists(pngp):
                shutil.copy2(pngp, os.path.join(final_dir, subset, "images", base + ".png"))

    copy_files(train_files, "train")
    copy_files(val_files, "val")
    copy_files(test_files, "test")
    print(f"[SPLIT] Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}")

# Appel
split_dataset(
    img_dir=AUG_IMAGE,
    lbl_dir=AUG_LABEL,
    final_dir=FINAL_DATA_DIR,
    train_ratio=0.8,
    val_ratio=0.1,
    test_ratio=0.1
)

import yaml
from collections import Counter

# 1) dictionnaire de mapping

class_mapping = {
    # Regroupement des classes de "Give way"
    "Give way (Yield)": "Give way",
    "Give way -Yield-": "Give way",

   #fusion pour des directions/flèches
    "Turn left ahead": "Turn left",
    "Turn left or straight ahead": "Turn left",
    "Turn right ahead": "Turn right",
    "No turning left": "No Left turn",
    "no turning left": "No Left turn",
    "no u turn": "No U turn",

    # STOP
    "Stop at customs": "Stop",

    "end of the speed limit": "End of all restrictions",
    "Parking allowed for 15min": "Parking",
     #weight limit
    "Axle weight limit-2ton": "Weight limit",
    "axle weight limit 30tonnes": "Weight limit",
    "No vehicles exceeding 12 tonnes": "Weight limit",
    "Weight limit-5ton": "Weight limit",
    "No vehicles exceeding weight shown": "Weight limit",
    # Classes de limite de vitesse :
    "speed limit-30": "Speed limit",
    "speed limit-50": "Speed limit",
    "speed limit-60": "Speed limit",
    "speed limit-70": "Speed limit",
    "speed limit-80": "Speed limit",
    "speed limit-90": "Speed limit",
    "speed limit-100": "Speed limit",
    "speed limit-110": "Speed limit",
    "speed-limit-120": "Speed limit",
    "lowspeed zone": "Speed limit",
}


# 2) Liste des noms dans `data.yaml`

names = [
    '0', '1', '100', '101', '102', '103', '105', '106', '107', '108', '109',
    '110', '111', '112', '113', '115', '116', '117', '12', '120', '121', '122',
    '123', '124', '125', '127', '128', '129', '131', '132', '133', '136', '137',
    '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148',
    '149', '15', '150', '153', '154', '155', '156', '158', '159', '16', '161',
    '163', '164', '166', '167', '168', '169', '17', '170', '171', '172', '173',
    '174', '175', '177', '178', '179', '18', '180', '181', '19', '2', '20', '21',
    '22', '23', '24', '27', '28', '29', '3', '31', '32', '33', '34', '35', '36',
    '39', '4', '40', '41', '42', '43', '45', '46', '47', '48', '49', '5', '50',
    '50 meters between vehicles', '51', '52', '53', '54', '55', '56', '57', '59',
    '60', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '73', '74',
    '76', '78', '79', '8', '81', '82', '83', '84', '85', '86', '87', '88', '89',
    '90', '91', '93', '94', '95', '97', '98', '99',
    'Advance direction sign exit ahead from other road than motorway or expressway',
    'Axle weight limit-2ton', 'Bus stop', 'Cattle', 'Crossroad intersection',
    'Crossroads', 'Cycle track', 'Cyclist and mopeds rides on carrigeway',
    'Cyclists', 'Dangerous shoulder', 'Dip', 'Direction sign exit sign',
    'Direction to be followed', 'End of all restrictions',
    'End of lane reserved for public transport', 'Falling rocks',
    'Filling station', 'First aid post', 'Give way (Yield)', 'Give way -Yield-',
    'Guarded level crossing ahead', 'Height limit-3.5m', 'Horn prohibited',
    'Hotel', 'Keep left', 'Left curve', 'Level crossing countdown marker',
    'Loose gravel', 'Main highways', 'Marking for sharp bends', 'Motorway',
    'Narrow bridge', 'Narrow road', 'National border', 'No Left turn',
    'No Right turn', 'No entry', 'No entry for Trucks', 'No entry for bicycles',
    'No entry for bullock carts', 'No entry for hand carts',
    'No entry for motor vehicles', 'No entry for pedestrians', 'No parking',
    'No passing', 'No snowmobiles', 'No stopping', 'No vehicles exceeding 12 tonnes',
    'No vehicles exceeding length shown', 'No vehicles in both directions',
    'No vehicles or combination of vehicles exceeding weight shown',
    'Oblique side road junction', 'One-way traffic', 'Parking',
    'Parking allowed for 15min', 'Passing without stopping prohibited',
    'Pedestrian crossing', 'Priority over oncoming vehicles', 'Refreshments',
    'Restaurant', 'Restriction zone', 'Right curve', 'Road hump',
    'Road number sign', 'Roadworks', 'Roundabout', 'School', 'Side road junction',
    'Slippery road', 'Speed refulcation bump', 'Staggered side road junction',
    'Steep ascent', 'Steep descent', 'Steep downhill', 'Steep uphill', 'Stop',
    'Stop at customs', 'Straight ahead',
    'Symbol plate for specified vehicle or road user category', 'T-junction',
    'Telephone', 'Traffic signals', 'Turn Right', 'Turn left', 'Turn left ahead',
    'Turn left or straight ahead', 'Turn right ahead', 'Uneven road',
    'Unguarded level crossing ahead', 'Unprotected quay', 'Weight limit-5ton',
    'Y-junction', 'adjoining way', 'axle weight limit 30tonnes',
    'end of the speed limit', 'exit', 'falling rocks (from) left',
    'falling rocks -from- left', 'length limit-10m', 'lowspeed zone',
    'no entry for bicycles and humans', 'no motorcycles', 'no turning left',
    'no u turn', 'snowmobiles', 'speed limit-100', 'speed limit-110',
    'speed limit-30', 'speed limit-50', 'speed limit-60', 'speed limit-70',
    'speed limit-80', 'speed limit-90', 'speed-limit-120', 'tunnel in 2 km',
    'two way traffic', 'warning wild animal'
]

# 3) Exemple de compteur d'occurrences actuelles

current_class_counts = Counter({
'57': 495, '109': 336, '12': 288, '73': 234, '131': 183, '111': 153,
                                 '13': 147, '118': 138, '2': 132, '5': 132, '121': 114,
                                 '23': 105, '4': 105, '141': 99, '68': 90, '64': 87, '114': 84,
                                 '142': 84, '62': 84, '72': 81, '122': 81, '11': 78, '149': 75, '92': 75,
                                 '123': 72, '34': 72, '241': 69, '173': 69, '159': 66, '188': 63, '65': 63,
                                 '199': 63, '212': 63, '116': 60, '259': 60, '31': 60, '25': 57, '16': 57,
                                 '113': 57, '15': 57, '262': 57, '26': 54, '60': 54, '203': 54, '256': 54,
                                 '102': 51, '263': 51, '234': 48, '53': 48, '45': 48, '70': 48, '9': 45,
                                 '49': 45, '132': 45, '140': 45, '143': 45, '146': 45, '32': 45, '258': 42,
                                 '90': 42, '28': 42, '24': 42, '198': 42, '239': 42, '252': 39, '19': 39,
                                 '20': 39, '135': 39, '84': 39, '180': 39, '36': 39, '179': 39, '17': 39,
                                 '66': 36, '69': 36, '191': 36, '63': 36, '215': 36, '218': 36, '214': 36,
                                 '127': 33, '115': 33, '232': 33, '183': 33, '137': 33, '195': 33, '48': 33,
                                 '124': 33, '100': 33, '106': 33, '82': 33, '184': 30, '97': 30, '58': 30,
                                 '253': 30, '80': 30, '213': 30, '88': 30, '110': 30, '139': 30, '7': 30,
                                 '230': 27, '181': 27, '222': 27, '223': 27, '117': 27, '50': 27, '150': 27,
                                 '201': 27, '104': 27, '105': 27, '167': 27, '211': 27, '52': 27, '240': 27,
                                 '200': 27, '138': 27, '95': 24, '245': 24, '254': 24, '153': 24, '107': 24,
                                 '76': 24, '204': 24, '29': 24, '98': 24, '86': 24, '101': 24, '257': 24,
                                 '1': 24, '251': 24, '238': 24,
                                 '61': 24, '194': 24, '18': 24, '38': 24, '163': 24, '197': 24, '119': 24,
                                 '217': 24, '157': 24, '112': 24, '207': 24, '210': 24, '55': 21, '190': 21,
                                 '145': 21, '27': 21, '220': 21, '250': 21, '136': 21, '161': 21, '51': 21, '94': 21,
                                 '172': 21, '40': 21, '171': 21, '56': 21, '8': 21, '162': 21, '151': 21, '205': 21,
                                 '202': 21, '77': 21, '236': 21, '247': 21, '206': 21, '225': 21, '54': 21, '156': 21, '99': 21,
                                 '192': 21, '147': 21, '79': 21, '35': 18, '182': 18, '130': 18, '93': 18, '3': 18, '261': 18, '75': 18,
                                 '242': 18, '120': 18, '260': 18, '41': 18, '42': 18, '91': 18, '87': 18, '175': 18, '126': 18,
                                 '158': 18, '108': 18, '103': 18, '89': 18, '85': 18, '46': 18, '125': 18, '170': 18, '174': 18, '235': 18, '249': 18, '168': 15, '224': 15, '133': 15, '193': 15, '67': 15, '30': 15, '185': 15, '78': 15, '160': 15, '189': 15, '83': 15, '196': 15, '22': 15, '229': 15, '74': 15, '216': 15, '37': 15, '178': 15, '47': 15, '219': 15, '81': 15, '209': 15, '228': 15, '227': 15, '177': 15, '134': 15, '237': 12, '208': 12, '59': 12, '44': 12, '233': 12, '128': 12, '255': 12, '33': 12, '221': 12, '231': 12, '155': 12, '154': 12, '71': 12, '144': 12, '43': 12, '148': 12, '164': 12, '96': 9, '6': 9, '186': 9, '169': 9, '129': 9, '226': 9, '39': 9, '248': 9, '187': 9})



# 4) Application du mapping

new_class_counts = Counter()
removed_classes = set()

for class_name, count in current_class_counts.items():

    mapped_name = class_mapping.get(class_name, class_name)


    if mapped_name in names:
        new_class_counts[mapped_name] += count
    else:

        removed_classes.add(class_name)


# 5) Génératuin la nouvelle liste 'names' + nouveau 'nc'

new_names = sorted(new_class_counts.keys())
nc = len(new_names)

# 6) Structure du futur YAML

data = {
  'train': "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/train/images",
  'val':   "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/val/images",
  'test':  "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images",
  'nc':    nc,
  'names': new_names
}

print("=== Classes hors scope ===")
print(removed_classes)

print("Nouveau YAML")
print(yaml.dump(data, sort_keys=False))

yaml_path = "/content/drive/MyDrive/DATASIGNALISATION/data.yaml"
with open(yaml_path, "w") as f:
    yaml.dump(data, f, sort_keys=False)
print(f"\nFichier YAML corrigé sauvegardé dans {yaml_path}")

import os
def validate_yolo_annotations(label_dir):

    for lbl_file in os.listdir(label_dir):
        if not lbl_file.endswith(".txt"):
            continue

        with open(os.path.join(label_dir, lbl_file), 'r') as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) != 5:
                    print(f"[Erreur] Mauvais format : {lbl_file} -> {line}")
                    continue

                cls_id, x_c, y_c, w, h = parts
                try:
                    x_c, y_c, w, h = float(x_c), float(y_c), float(w), float(h)
                    if not (0 <= x_c <= 1 and 0 <= y_c <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                        print(f"[Erreur] Valeur hors bornes dans : {lbl_file} -> {line}")
                except ValueError:
                    print(f"[Erreur] Valeur non valide dans : {lbl_file} -> {line}")

validate_yolo_annotations("/content/drive/MyDrive/DATASIGNALISATION/final_dataset/train/labels")

!pip install ultralytics

!pip install torch torchvision matplotlib numpy opencv-python

from ultralytics import YOLO

# Load a pre-trained YOLOv10n model
model = YOLO("/content/drive/MyDrive/DATASIGNALISATION/yolov10n.pt")

from ultralytics import YOLO

# Load a pre-trained YOLOv10n model
model = YOLO("/content/drive/MyDrive/DATASIGNALISATION/yolov10m.pt")

# Lancer l'entraînement
model.train(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml",
            epochs=10,
            imgsz=640,
            batch=8,
            name="YOLOv10m_training")

# 2. Test sur le dataset de test

results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")

precision = results.box.p
recall = results.box.r
mAP50 = results.box.map50
mAP50_95 = results.box.map
print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")

# Graphe des métriques
metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]
# Use the mean values for the bar chart
values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]

plt.figure(figsize=(10, 5))
plt.bar(metrics, values)
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()


# 4. Visualisation des prédictions

test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"
predictions = model.predict(source=test_images_dir, save=True, save_txt=True)

# Visualisation de  quelques exemples
import glob
from IPython.display import Image, display

predicted_images = glob.glob("runs/predict/*/*.jpg")

# Affichage des 5 premières images prédites
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))

from ultralytics import YOLO

# Load a pre-trained YOLOv10n model
model = YOLO("/content/drive/MyDrive/DATASIGNALISATION/yolov10m.pt")

# Lancer l'entraînement
model.train(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml",
            epochs=50,
            imgsz=640,
            batch=16,
            name="YOLOv10m_training2")

# 1. Test sur le dataset de test


results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")


precision = results.box.p
recall = results.box.r
mAP50 = results.box.map50
mAP50_95 = results.box.map

# Afficher les métriques
print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")
import matplotlib.pyplot as plt

# Labels des métriques
metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]

# Utiliser les moyennes pour créer le graphique
values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]

# Création du graphique
plt.figure(figsize=(10, 5))
plt.bar(metrics, values, color="skyblue")
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()

test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"


predictions = model.predict(source=test_images_dir, save=True, save_txt=True)



import glob
from IPython.display import Image, display


predicted_images = glob.glob("runs/predict/*/*.jpg")


print("Visualisation des images prédites :")
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))

# Lancer l'entraînement
model.train(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml",
            epochs=100,
            imgsz=640,
            batch=16,
            name="YOLOv10m_training2")

results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")


precision = results.box.p
recall = results.box.r
mAP50 = results.box.map50
mAP50_95 = results.box.map

# Afficher les métriques
print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")




metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]

values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]

# Création du graphique
plt.figure(figsize=(10, 5))
plt.bar(metrics, values, color="skyblue")
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()


test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"


predictions = model.predict(source=test_images_dir, save=True, save_txt=True)



predicted_images = glob.glob("runs/detect/predict/*/*.jpg")


print("Visualisation des prédictions sur le dataset de test :")
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))

from ultralytics import YOLO

# Load a pre-trained YOLOv10n model
model = YOLO("/content/drive/MyDrive/DATASIGNALISATION/yolov10s.pt")

# Lancer l'entraînement
model.train(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml",
            epochs=100,
            imgsz=640,
            batch=16,
            name="YOLOv10s_training")

results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")


precision = results.box.p
recall = results.box.r
mAP50 = results.box.map50
mAP50_95 = results.box.map


print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")



metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]


values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]

plt.figure(figsize=(10, 5))
plt.bar(metrics, values, color="skyblue")
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()

test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"


predictions = model.predict(source=test_images_dir, save=True, save_txt=True)



predicted_images = glob.glob("runs/detect/predict/*/*.jpg")


print("Visualisation des prédictions sur le dataset de test :")
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))

results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")


precision = results.box.p  # Précision
recall = results.box.r     # Rappel
mAP50 = results.box.map50  # mAP@50
mAP50_95 = results.box.map   # mAP@50-95

s
print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")

import matplotlib.pyplot as plt

metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]


values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]

plt.figure(figsize=(10, 5))
plt.bar(metrics, values, color="skyblue")
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()

test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"


predictions = model.predict(source=test_images_dir, save=True, save_txt=True)

import cv2
import glob
from IPython.display import Image, display


predicted_images = glob.glob("runs/detect/predict/*/*.jpg")

print("Visualisation des prédictions sur le dataset de test :")
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))

from ultralytics import YOLO

# Load a pre-trained YOLOv10n model
model = YOLO("/content/drive/MyDrive/DATASIGNALISATION/yolov10b.pt")

# Lancer l'entraînement
model.train(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml",
            epochs=100,
            imgsz=640,
            batch=16,
            name="YOLOv10b_training")

results = model.val(data="/content/drive/MyDrive/DATASIGNALISATION/data_filtered.yaml")

precision = results.box.p
recall = results.box.r
mAP50 = results.box.map50
mAP50_95 = results.box.map


print(f"Précision : {precision.mean():.2f}")
print(f"Rappel : {recall.mean():.2f}")
print(f"mAP@50 : {mAP50.mean():.2f}")
print(f"mAP@50-95 : {mAP50_95.mean():.2f}")


metrics = ["Precision", "Recall", "mAP@50", "mAP@50-95"]

values = [precision.mean(), recall.mean(), mAP50.mean(), mAP50_95.mean()]


plt.figure(figsize=(10, 5))
plt.bar(metrics, values, color="skyblue")
plt.title("Métriques de performance sur le dataset de test")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.show()

test_images_dir = "/content/drive/MyDrive/DATASIGNALISATION/final_dataset/test/images"


predictions = model.predict(source=test_images_dir, save=True, save_txt=True)



predicted_images = glob.glob("runs/detect/predict/*/*.jpg")

print("Visualisation des prédictions sur le dataset de test :")
for img_path in predicted_images[:5]:
    display(Image(filename=img_path))